package chat

import "github.com/docker/cagent/pkg/tools"

type MessageRole string

const (
	MessageRoleSystem    MessageRole = "system"
	MessageRoleUser      MessageRole = "user"
	MessageRoleAssistant MessageRole = "assistant"
	MessageRoleTool      MessageRole = "tool"
)

type MessagePartType string

const (
	MessagePartTypeText     MessagePartType = "text"
	MessagePartTypeImageURL MessagePartType = "image_url"
)

type ImageURLDetail string

const (
	ImageURLDetailHigh ImageURLDetail = "high"
	ImageURLDetailLow  ImageURLDetail = "low"
	ImageURLDetailAuto ImageURLDetail = "auto"
)

// FileSourceType indicates how the file should be referenced in API calls
type FileSourceType string

const (
	// FileSourceTypeNone means no file reference, use URL or base64
	FileSourceTypeNone FileSourceType = ""
	// FileSourceTypeFileID means the file was uploaded and should be referenced by ID
	FileSourceTypeFileID FileSourceType = "file_id"
	// FileSourceTypeFileURI means the file was uploaded and should be referenced by URI (Gemini)
	FileSourceTypeFileURI FileSourceType = "file_uri"
	// FileSourceTypeLocalPath means the file is a local path that needs to be uploaded/converted
	FileSourceTypeLocalPath FileSourceType = "local_path"
)

// FileReference contains information about a file attachment
type FileReference struct {
	// SourceType indicates how this file should be referenced
	SourceType FileSourceType `json:"source_type,omitempty"`
	// FileID is the provider-specific file identifier (for FileSourceTypeFileID)
	FileID string `json:"file_id,omitempty"`
	// FileURI is the file URI (for FileSourceTypeFileURI, used by Gemini)
	FileURI string `json:"file_uri,omitempty"`
	// LocalPath is the path to a local file (for FileSourceTypeLocalPath)
	LocalPath string `json:"local_path,omitempty"`
	// MimeType is the MIME type of the file
	MimeType string `json:"mime_type,omitempty"`
	// Provider identifies which provider this reference is for (when uploaded)
	Provider string `json:"provider,omitempty"`
}

type MessageImageURL struct {
	// URL contains a data URL (base64) or a public HTTP(S) URL
	URL    string         `json:"url,omitempty"`
	Detail ImageURLDetail `json:"detail,omitempty"`

	// FileRef contains file reference info when the image was uploaded via Files API
	// or references a local file path that needs to be processed
	FileRef *FileReference `json:"file_ref,omitempty"`
}

type Message struct {
	Role         MessageRole   `json:"role"`
	Content      string        `json:"content"`
	MultiContent []MessagePart `json:"multi_content,omitempty"`

	// This property is used for the "reasoning" feature supported by deepseek-reasoner
	// which is not in the official documentation.
	// the doc from deepseek:
	// - https://api-docs.deepseek.com/api/create-chat-completion#responses
	ReasoningContent string `json:"reasoning_content,omitempty"`

	// ThinkingSignature is used for Anthropic's extended thinking feature
	ThinkingSignature string `json:"thinking_signature,omitempty"`

	ThoughtSignature []byte `json:"thought_signature,omitempty"`

	FunctionCall *tools.FunctionCall `json:"function_call,omitempty"`

	// For Role=assistant prompts this may be set to the tool calls generated by the model, such as function calls.
	ToolCalls []tools.ToolCall `json:"tool_calls,omitempty"`

	// ToolDefinitions contains the definitions of tools referenced in ToolCalls.
	// This is used to provide tool metadata (name, description, category) when loading historical sessions.
	ToolDefinitions []tools.Tool `json:"tool_definitions,omitempty"`

	// For Role=tool prompts this should be set to the ID given in the assistant's prior request to call a tool.
	ToolCallID string `json:"tool_call_id,omitempty"`

	CreatedAt string `json:"created_at,omitempty"`

	// Usage tracks token usage for this message (only set for assistant messages)
	Usage *Usage `json:"usage,omitempty"`

	// Model is the model that generated this message (only set for assistant messages)
	Model string `json:"model,omitempty"`

	// Cost is the cost of this message in dollars (only set for assistant messages)
	Cost float64 `json:"cost,omitempty"`

	// CacheControl indicates whether this message is a cached message (only used by anthropic)
	CacheControl bool `json:"cache_control,omitempty"`
}

type MessagePart struct {
	Type     MessagePartType  `json:"type,omitempty"`
	Text     string           `json:"text,omitempty"`
	ImageURL *MessageImageURL `json:"image_url,omitempty"`
}

// FinishReason represents the reason why the model finished generating a response
type FinishReason string

const (
	// FinishReasonStop means the model reached a natural stopping point or the max tokens
	FinishReasonStop FinishReason = "stop"
	// FinishReasonLength means the model reached the token limit
	FinishReasonLength FinishReason = "length"
	// FinishReasonToolCalls means the model called a tool
	FinishReasonToolCalls FinishReason = "tool_calls"
	// FinishReasonNull means no finish reason was provided
	FinishReasonNull FinishReason = "null"
)

// MessageDelta represents a delta/chunk in a streaming response
type MessageDelta struct {
	Role              string              `json:"role,omitempty"`
	Content           string              `json:"content,omitempty"`
	ReasoningContent  string              `json:"reasoning_content,omitempty"`
	ThinkingSignature string              `json:"thinking_signature,omitempty"`
	ThoughtSignature  []byte              `json:"thought_signature,omitempty"`
	FunctionCall      *tools.FunctionCall `json:"function_call,omitempty"`
	ToolCalls         []tools.ToolCall    `json:"tool_calls,omitempty"`
}

// MessageStreamChoice represents a choice in a streaming response
type MessageStreamChoice struct {
	Index        int          `json:"index"`
	Delta        MessageDelta `json:"delta"`
	FinishReason FinishReason `json:"finish_reason,omitempty"`
}

// MessageStreamResponse represents a streaming response from the model
type MessageStreamResponse struct {
	ID      string                `json:"id"`
	Object  string                `json:"object"`
	Created int64                 `json:"created"`
	Model   string                `json:"model"`
	Choices []MessageStreamChoice `json:"choices"`
	Usage   *Usage                `json:"usage,omitempty"`
}

type Usage struct {
	InputTokens       int64 `json:"input_tokens"`
	OutputTokens      int64 `json:"output_tokens"`
	CachedInputTokens int64 `json:"cached_input_tokens"`
	CacheWriteTokens  int64 `json:"cached_write_tokens"`
	ReasoningTokens   int64 `json:"reasoning_tokens,omitempty"`
}

// MessageStream interface represents a stream of chat completions
type MessageStream interface {
	// Recv gets the next completion chunk
	Recv() (MessageStreamResponse, error)
	// Close closes the stream
	Close()
}
